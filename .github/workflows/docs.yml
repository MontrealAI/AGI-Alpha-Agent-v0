---
name: "ðŸ“š Docs"

on:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build-deploy:
    runs-on: ubuntu-latest
    env:
      SANDBOX_IMAGE: ghcr.io/example/selfheal-sandbox:latest
      PYODIDE_BASE_URL: https://cdn.jsdelivr.net/pyodide/v0.28.0/full
      HF_GPT2_BASE_URL: https://huggingface.co/openai-community/gpt2/resolve/main
      FETCH_ASSETS_ATTEMPTS: '5'
      CI: 'true'
      # Keep the asset mirrors pinned to official hosts.
      # Optional environment variables for asset downloads. See
      # scripts/fetch_assets.py for details.
      # HF_GPT2_BASE_URL overrides the default Hugging Face mirror.
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/ensure-owner
      - uses: actions/checkout@v4.1.5 # 44c2b7a8a4ea60a981eaca3cf939b5f4305c123b
      - name: Set up Python
        uses: actions/setup-python@v5.6.0 # a26af69be951a213d495a4c3e4e4022e16d87065
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: 'requirements.lock'

      - name: Cache pre-commit
        uses: actions/cache@v4.2.3 # 5a3ec84eff668545956fd18022155c47e93e2684
        with:
          path: .cache/pre-commit
          key: ${{ runner.os }}-precommit-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            ${{ runner.os }}-precommit-
      - name: Install Ruff
        run: pip install ruff
      - name: Install docs dependencies
        run: pip install -r requirements-docs.txt
      - name: Install project dependencies
        run: python check_env.py --auto-install
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Cache sandbox layers
        uses: actions/cache@v4.2.3 # 5a3ec84eff668545956fd18022155c47e93e2684
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-sandbox-${{ github.sha }}
          restore-keys: ${{ runner.os }}-sandbox-
      - name: Build sandbox image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: sandbox.Dockerfile
          tags: $SANDBOX_IMAGE
          load: true
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
      - name: Update cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache
      - uses: actions/setup-node@v4.4.0 # 49933ea5288caeca8642d1e84afbd3f7d6820020
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'
          cache-dependency-path: |
            alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/package-lock.json
            alpha_factory_v1/core/interface/web_client/package-lock.json
      - name: Install Insight Browser dependencies
        run: npm ci --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
      - name: Install Web client dependencies
        run: npm ci --prefix alpha_factory_v1/core/interface/web_client
      - name: Update browserslist database
        run: npx update-browserslist-db@latest --agree-to-terms
      - name: Install pre-commit
        run: pip install pre-commit==4.2.0
        env:
          PRE_COMMIT_HOME: .cache/pre-commit
      - name: Run pre-commit checks
        run: pre-commit run --all-files
        env:
          PRE_COMMIT_HOME: .cache/pre-commit
      - name: Install Playwright browsers
        run: npx playwright install --with-deps
      - name: Make scripts executable
        run: chmod +x ./scripts/*.sh
      - name: Compute asset cache key
        id: asset-key
        run: |
          key=$(python - <<'EOF'
          import hashlib
          import os
          import scripts.fetch_assets as fa

          env_data = f"{os.getenv('PYODIDE_BASE_URL', '')}:{os.getenv('HF_GPT2_BASE_URL', '')}"
          data = (
              fa.CHECKSUMS["pyodide.asm.wasm"]
              + fa.CHECKSUMS["pyodide.js"]
              + fa.CHECKSUMS["pyodide-lock.json"]
              + fa.CHECKSUMS["pytorch_model.bin"]
              + env_data
          )
          print(hashlib.sha256(data.encode()).hexdigest())
          EOF
          )
          echo "key=$key" >> "$GITHUB_OUTPUT"
      - name: Cache Pyodide and GPT-2 assets
        id: asset-cache
        uses: actions/cache@v4.2.3 # 5a3ec84eff668545956fd18022155c47e93e2684
        with:
          path: |
            alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/wasm
            alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/wasm_llm
          key: assets-${{ steps.asset-key.outputs.key }}
          restore-keys: assets-
      - name: Fetch browser assets
        run: python scripts/fetch_assets.py
      - name: Verify browser assets
        run: python scripts/fetch_assets.py --verify-only
      - name: Update build manifest
        run: python scripts/generate_build_manifest.py
      - name: Build and deploy gallery
        env:
          PYODIDE_BASE_URL: ${{ env.PYODIDE_BASE_URL }}
          HF_GPT2_BASE_URL: ${{ env.HF_GPT2_BASE_URL }}
          CI_SKIP_ENV_CHECK: '1'
        run: |
          export CI=true
          ./scripts/edge_human_knowledge_pages_sprint.sh
      - name: Verify downloaded assets
        run: python scripts/fetch_assets.py --verify-only
      - name: Check internal links
        uses: lycheeverse/lychee-action@v1.7.0
        with:
          args: --offline --base ./site ./site/**/*.html
          fail: true
