# üåê Alpha-AGI Insight CI ‚Äî GitHub Actions Workflow
#
# Validates the demo with lint, type checks, unit tests and Docker build.
# Runs on pushes and pull requests to `main`, plus optional manual dispatch.
# Manual runs remain gated by the owner-check job to block untrusted triggers.
# Deploys a Docker image with rollback on failure.
# Later jobs run unconditionally but check `needs.owner-check.result == 'success'`
# so they skip when owner verification fails.
# Verified 2025-08-03T15:17:11Z via `python tools/update_actions.py` and `pre-commit`.
# The Python matrix targets stable versions 3.11‚Äì3.12 while upstream
# PyTorch finalizes reliable 3.13 builds.
# Matrix verifies long-term support versions 3.11‚Äì3.12.
# Jobs cover linting, unit tests, Windows and macOS smoke tests,
# full documentation builds, Docker image creation and deployment.
# After editing this workflow run:
#   python tools/update_actions.py
#   pre-commit run --files .github/workflows/ci.yml
name: "üöÄ CI ‚Äî Insight Demo"

on:
  push:
    branches: ["main"]
    tags: ["v*", "release-*"]
  pull_request:
    branches: ["main"]
  merge_group:
  workflow_dispatch:
    inputs:
      a11y-threshold:
        description: "Minimum Axe accessibility score"
        required: false
        default: "95"

permissions:
  contents: read
  actions: write
  # Note: GitHub rejects workflows with unsupported permission keys, so keep
  # this list limited to scopes GitHub Actions recognizes.
  # Allowed keys: actions, checks, contents, deployments,
  # id-token, issues, discussions, packages, pages, pull-requests,
  # repository-projects, security-events, statuses.

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  DOCKER_IMAGE: agi-insight-demo
  SANDBOX_IMAGE: selfheal-sandbox:latest
  PYTHONUTF8: '1'
  PIP_NO_INPUT: '1'
  COSIGN_CERT_IDENTITY_REGEX: https://github.com/${{ github.repository }}/.github/workflows/ci.yml@.*
  COSIGN_CERT_ISSUER: https://token.actions.githubusercontent.com
  PLAYWRIGHT_BROWSERS_PATH: ${{ github.workspace }}/.tmp/ms-playwright
  FETCH_ASSETS_DIR: ${{ github.workspace }}/.tmp/insight-assets
  INSIGHT_ASSET_ROOT: ${{ github.workspace }}/.tmp/insight-assets
  PYODIDE_CACHE_DIR: ${{ github.workspace }}/.tmp/pyodide-cache
  NODE_LOCKFILES: |
    alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/package-lock.json
    alpha_factory_v1/core/interface/web_client/package-lock.json
    alpha_factory_v1/core/interface/web_client/staking/package-lock.json
    alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/web_client/package-lock.json
  PYODIDE_BASE_URL: https://cdn.jsdelivr.net/pyodide/v0.28.0/full
  HF_GPT2_BASE_URL: https://huggingface.co/openai-community/gpt2/resolve/main
  # Guard `inputs` usage so push/PR events (which do not populate the
  # `inputs` context) still receive the default threshold instead of
  # erroring during expression evaluation.
  A11Y_THRESHOLD: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs['a11y-threshold'] || '95' }}
  FETCH_ASSETS_ATTEMPTS: '5'
  FETCH_ASSETS_BACKOFF: '2'
  AGIALPHA_ADDRESS: "0xa61a3b3a130a9c20768eebf97e21515a6046a1fa"
  AGIALPHA_DECIMALS: 18

jobs:

  owner-check:
    name: "Verify owner"
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      repo_owner_lower: ${{ steps.owner-manual.outputs.repo_owner_lower || steps.owner-auto.outputs.repo_owner_lower }}
    steps:
      # Checkout repository so the local ensure-owner action is available
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 0
      - id: owner-manual
        if: github.event_name == 'workflow_dispatch'
        # Local composite action validates the workflow initiator
        # Ensure checkout ran beforehand so action files are available.
        # Without a prior checkout step GitHub Actions reports:
        # "Can't find 'action.yml' or 'Dockerfile' under '.github/actions/ensure-owner'"
        # The ensure-owner action fails fast if someone other than the
        # repository owner triggers the workflow. This protects subsequent
        # jobs from running under untrusted contexts.
        uses: ./.github/actions/ensure-owner
      - id: owner-auto
        if: github.event_name != 'workflow_dispatch'
        run: |
          owner_lower="${GITHUB_REPOSITORY_OWNER,,}"
          echo "repo_owner_lower=${owner_lower}" >> "$GITHUB_OUTPUT"

  workflow-lint:
    name: "‚úÖ Actionlint"
    if: ${{ always() && needs.owner-check.result == 'success' }}
    needs: owner-check
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
      checks: write
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: Lint workflows
        uses: reviewdog/action-actionlint@437bbe918b0d29544cbf9e8b1d63fe6f4e7a881d # v1
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          fail_level: error

  lint-type:
    name: "üßπ Ruff + üè∑Ô∏è Mypy (${{ matrix.python-version }})"
    if: ${{ always() && needs.owner-check.result == 'success' }}
    needs: owner-check
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        # PyTorch's triton wheels do not yet support Python 3.13, so keep tests on
        # 3.11‚Äì3.12 until upstream publishes compatible builds.
        python-version: ["3.11", "3.12"]
    steps:
      # checkout required for local composite actions
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: Check for binary diffs
        run: python scripts/check_no_binary_diff.py
      - name: Ensure pip cache directory
        shell: bash
        run: |
          python - <<'PY'
          import subprocess
          import sys
          from pathlib import Path

          try:
            cache_dir = subprocess.check_output(
                [sys.executable, "-m", "pip", "cache", "dir"],
                text=True,
            ).strip()
          except Exception:
            cache_dir = None

          Path(cache_dir or Path("~/.cache/pip").expanduser()).expanduser().mkdir(
              parents=True,
              exist_ok=True,
          )
          PY
      - name: Verify $AGIALPHA configuration
        run: python scripts/check_agialpha_config.py
      - uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
        with:
          python-version: ${{ matrix.python-version }}
          cache: pip
          cache-dependency-path: |
            requirements.lock
            requirements-dev.lock
            alpha_factory_v1/backend/requirements-lock.txt
      - name: Show tool versions
        run: |
          python --version
          docker --version
          docker compose version
          git --version

      - name: Cache pre-commit
        uses: actions/cache@v5.0.2 # 8b402f58fbc84540c8b491a91e594a4576fec3d7
        with:
          path: .cache/pre-commit
          key: ${{ runner.os }}-precommit-py${{ matrix.python-version }}-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            ${{ runner.os }}-precommit-py${{ matrix.python-version }}-
      - name: Install lint tools
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.lock
      - name: Install pre-commit
        run: pip install pre-commit==4.2.0
        env:
          PRE_COMMIT_HOME: .cache/pre-commit
      - name: Run pre-commit checks
        run: |
          from_ref="${{ github.event.before }}"
          if [ -n "$from_ref" ] && git rev-parse --verify "$from_ref^{commit}" >/dev/null 2>&1; then
            pre-commit run --from-ref "$from_ref" --to-ref "${{ github.sha }}"
          else
            echo "::notice::Falling back to pre-commit --all-files (missing or unreachable from_ref)."
            pre-commit run --all-files
          fi
        env:
          PRE_COMMIT_HOME: .cache/pre-commit
          SKIP: eslint-insight-browser
      - name: Fail on uncommitted changes
        run: |
          git --no-pager diff
          if ! git diff --quiet; then
            echo "::error::Uncommitted changes detected. Run pre-commit locally."
            exit 1
          fi
      - name: Ruff lint
        run: ruff check alpha_factory_v1/demos/alpha_agi_insight_v1
      - name: Mypy type-check
        # Use configuration defaults to restrict analysis to the src package
        run: mypy --config-file mypy.ini

  insight-eslint:
    name: "üß™ Insight Browser ESLint"
    if: ${{ always() && needs.owner-check.result == 'success' }}
    needs: owner-check
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      NPM_CONFIG_CACHE: ${{ github.workspace }}/.npm-cache/insight-browser
      NPM_CONFIG_FUND: 'false'
      NPM_CONFIG_AUDIT: 'false'
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - uses: actions/setup-node@2028fbc5c25fe9cf00d9f06a71cc4710d4507903 # v6.0.0
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'
          cache-dependency-path: ${{ env.NODE_LOCKFILES }}
      - name: Cache Playwright browsers
        uses: actions/cache@v5.0.2 # 8b402f58fbc84540c8b491a91e594a4576fec3d7
        with:
          path: ${{ env.PLAYWRIGHT_BROWSERS_PATH }}
          key: ${{ runner.os }}-playwright-${{ hashFiles('alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-
      - name: Configure npm
        run: |
          npm config set fund false
          npm config set audit false
      - name: Clean Insight Browser install
        run: |
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          rm -rf "$NPM_CONFIG_CACHE"
      - name: Install insight browser dependencies
        run: |
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          npm ci --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
      - name: Lint insight browser
        run: npm --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 run lint

  tests:
    name: "‚úÖ Pytest (${{ matrix.python-version }})"
    if: ${{ always() && needs.owner-check.result == 'success' }}
    needs: owner-check
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      pull-requests: write
    env:
      SANDBOX_IMAGE: selfheal-sandbox:latest
      PERCY_TOKEN: ${{ secrets.PERCY_TOKEN }}
      NPM_CONFIG_CACHE: ${{ github.workspace }}/.npm-cache/tests
      NPM_CONFIG_FUND: 'false'
      NPM_CONFIG_AUDIT: 'false'
    strategy:
      fail-fast: false
      matrix:
        # Retain 3.11‚Äì3.12 until upstream publishes stable PyTorch wheels for 3.13.
        python-version: ["3.11", "3.12"]
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: Check for binary diffs (pre-build)
        run: python scripts/check_no_binary_diff.py
      - name: Ensure pip cache directory
        shell: bash
        run: |
          python - <<'PY'
          import subprocess
          import sys
          from pathlib import Path

          try:
            cache_dir = subprocess.check_output(
                [sys.executable, "-m", "pip", "cache", "dir"],
                text=True,
            ).strip()
          except Exception:
            cache_dir = None

          Path(cache_dir or Path("~/.cache/pip").expanduser()).expanduser().mkdir(
              parents=True,
              exist_ok=True,
          )
          PY
      - name: Verify $AGIALPHA configuration
        run: python scripts/check_agialpha_config.py
      - uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
        with:
          python-version: ${{ matrix.python-version }}
          cache: pip
          cache-dependency-path: |
            requirements.lock
            requirements-dev.lock
            alpha_factory_v1/backend/requirements-lock.txt
      - name: Free disk space
        run: bash scripts/ci_free_disk.sh
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.lock
          pip install -r requirements-dev.lock
          pip install -r alpha_factory_v1/backend/requirements-lock.txt
      - name: Verify environment
        shell: bash
        run: |
          python scripts/check_python_deps.py
          python check_env.py --auto-install --demo macro_sentinel
      # Install Node.js and cache dependencies using both lockfiles
      - uses: actions/setup-node@2028fbc5c25fe9cf00d9f06a71cc4710d4507903 # v6.0.0
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'
          cache-dependency-path: ${{ env.NODE_LOCKFILES }}
      - name: Cache Playwright browsers
        uses: actions/cache@v5.0.2 # 8b402f58fbc84540c8b491a91e594a4576fec3d7
        with:
          path: ${{ env.PLAYWRIGHT_BROWSERS_PATH }}
          key: ${{ runner.os }}-playwright-${{ hashFiles('alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-
      - name: Configure npm
        run: |
          npm config set fund false
          npm config set audit false
      - uses: ./.github/actions/setup-env
        with:
          sandbox-image: ${{ env.SANDBOX_IMAGE }}
        env:
          SANDBOX_IMAGE: ${{ env.SANDBOX_IMAGE || 'selfheal-sandbox:latest' }}
      - uses: ./.github/actions/setup-insight-assets
      - name: Install insight browser dependencies
        run: |
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          npm ci --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
      # asset verification handled by setup-insight-assets
      - name: Update browserslist database (Insight demo)
        working-directory: alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
        run: npx update-browserslist-db --update-db --yes
      - name: Audit insight browser dependencies
        # Fail only on critical vulnerabilities to reduce noise while still blocking
        # severe supply-chain issues. High/Moderate advisories frequently surface in
        # transient transitive dependencies and are tracked separately via Dependabot.
        run: npm --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 audit --production --audit-level=critical
      - name: Run insight browser tests
        env:
          CI: 'true'
        run: npm --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 test
      - name: Install web dependencies
        run: |
          rm -rf alpha_factory_v1/core/interface/web_client/node_modules
          npm ci --prefix alpha_factory_v1/core/interface/web_client
      - name: Update browserslist database (Web client)
        working-directory: alpha_factory_v1/core/interface/web_client
        run: npx update-browserslist-db --update-db --yes
      - name: Audit web dependencies
        # Aligns with the reduced-noise audit gate above while still enforcing
        # actionable supply-chain hygiene on the primary web client bundle.
        run: npm --prefix alpha_factory_v1/core/interface/web_client audit --production --audit-level=critical
      - name: Type check insight browser
        run: npm --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 run typecheck
      - name: Verify protobuf
        run: make proto-verify
      - name: Clean caches before pytest
        run: |
          python -m pip cache purge
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          rm -rf alpha_factory_v1/core/interface/web_client/node_modules
          rm -rf "$NPM_CONFIG_CACHE"
          rm -rf ~/.cache/pip ~/.cache/pypoetry ~/.cache/node-gyp
          df -h
      - name: Run tests with coverage
        shell: bash
        run: |
          python check_env.py --auto-install${WHEELHOUSE:+ --wheelhouse "$WHEELHOUSE"}
          mkdir -p artifacts/test-reports
          pytest --cov --cov-report=xml:artifacts/coverage.xml --cov-fail-under=80 --junitxml=artifacts/test-reports/pytest.xml
      - name: Mutation tests
        if: matrix.python-version == '3.11'
        run: |
          mutmut run --paths-to-mutate alpha_factory_v1/demos/alpha_agi_insight_v1/src --runner "pytest -q"
      - name: Run benchmark
        run: |
          pytest tests/test_benchmark.py -q
          cat tests/benchmarks/latest.json
      - name: Check benchmark result
        id: bench-check
        run: |
          if [[ -f tests/benchmarks/latest.json ]]; then echo "found=true" >> "$GITHUB_OUTPUT"; fi
      - name: Upload benchmark results
        if: steps.bench-check.outputs.found == 'true'
        uses: actions/upload-artifact@v6.0.0 # b7c566a772e6b6bfb58ed0dc250532a479d7789f
        with:
          name: benchmark-results
          path: tests/benchmarks/latest.json
      - name: Generate benchmark comment
        run: |
          python - <<'PY'
          import json
          data=json.load(open('tests/benchmarks/latest.json'))
          with open('bench.txt','w') as f:
              f.write(f"p95 runtime: {data['p95']:.4f}s\n")
              f.write(f"tokens used: {data['tokens']}\n")
          PY
      - name: Comment benchmark
        if: ${{ github.event.pull_request }}
        uses: marocchino/sticky-pull-request-comment@v2.9.4 # 773744901bac0e8cbb5a0dc842800d45e9b2b405
        with:
          header: benchmark
          path: bench.txt
      - name: Check coverage report
        id: coverage-check
        run: |
          if [[ -f artifacts/coverage.xml ]]; then echo "found=true" >> "$GITHUB_OUTPUT"; fi
      - name: Upload pytest results
        if: always()
        uses: actions/upload-artifact@v6.0.0 # b7c566a772e6b6bfb58ed0dc250532a479d7789f
        with:
          name: pytest-${{ matrix.python-version }}
          path: artifacts/test-reports/pytest.xml
          if-no-files-found: warn
      - name: Upload coverage
        if: steps.coverage-check.outputs.found == 'true'
        uses: actions/upload-artifact@v6.0.0 # b7c566a772e6b6bfb58ed0dc250532a479d7789f
        with:
          name: coverage-xml
          path: artifacts/coverage.xml

  windows-smoke:
    name: "Windows Smoke"
    if: ${{ always() && needs.owner-check.result == 'success' }}
    needs: owner-check
    runs-on: windows-latest
    timeout-minutes: 30
    env:
      NPM_CONFIG_CACHE: ${{ github.workspace }}/.npm-cache/windows-smoke
      NPM_CONFIG_FUND: 'false'
      NPM_CONFIG_AUDIT: 'false'
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: Check for binary diffs (pre-build)
        run: python scripts/check_no_binary_diff.py
      - name: Ensure pip cache directory
        shell: bash
        run: |
          python - <<'PY'
          import subprocess
          import sys
          from pathlib import Path

          try:
            cache_dir = subprocess.check_output(
                [sys.executable, "-m", "pip", "cache", "dir"],
                text=True,
            ).strip()
          except Exception:
            cache_dir = None

          Path(cache_dir or Path("~/.cache/pip").expanduser()).expanduser().mkdir(
              parents=True,
              exist_ok=True,
          )
          PY
      - uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
        with:
          # Use 3.11 to align with available CPU-only PyTorch wheels on Windows
          python-version: '3.11'
          architecture: 'x64'
          cache: pip
          cache-dependency-path: 'requirements.lock'
      - name: Verify $AGIALPHA configuration
        run: python scripts/check_agialpha_config.py
      - name: Install dependencies  # use CPU-only lock file on Windows
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-demo-cpu.lock
          pip install -r requirements-dev.lock
      - uses: actions/setup-node@2028fbc5c25fe9cf00d9f06a71cc4710d4507903 # v6.0.0
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'
          cache-dependency-path: ${{ env.NODE_LOCKFILES }}
      - name: Cache Playwright browsers
        uses: actions/cache@v5.0.2 # 8b402f58fbc84540c8b491a91e594a4576fec3d7
        with:
          path: ${{ env.PLAYWRIGHT_BROWSERS_PATH }}
          key: ${{ runner.os }}-playwright-${{ hashFiles('alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-
      - name: Configure npm
        run: |
          npm config set fund false
          npm config set audit false
      - name: Show tool versions
        shell: bash
        run: |
          set -euo pipefail
          python --version
          node --version
          git --version
          if command -v docker >/dev/null 2>&1; then
            docker --version
            docker compose version || docker-compose version
          else
            echo "::notice::Docker not available on windows-latest runner"
          fi
      - name: Verify environment
        run: |
          python scripts/check_python_deps.py
          python check_env.py --auto-install
      - uses: ./.github/actions/setup-insight-assets
      - name: Build web assets
        shell: bash
        run: |
          set -e
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          npm ci --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
          (cd alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 && \
            npx update-browserslist-db --update-db --yes)
          npm run --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 build
      - name: Run smoke tests
        run: pytest -m smoke -q

  macos-smoke:
    name: "macOS Smoke"
    if: ${{ always() && needs.owner-check.result == 'success' }}
    needs: owner-check
    runs-on: macos-latest
    timeout-minutes: 30
    env:
      NPM_CONFIG_CACHE: ${{ github.workspace }}/.npm-cache/macos-smoke
      NPM_CONFIG_FUND: 'false'
      NPM_CONFIG_AUDIT: 'false'
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: Check for binary diffs (pre-build)
        run: python scripts/check_no_binary_diff.py
      - name: Ensure pip cache directory
        shell: bash
        run: |
          python - <<'PY'
          import subprocess
          import sys
          from pathlib import Path

          try:
            cache_dir = subprocess.check_output(
                [sys.executable, "-m", "pip", "cache", "dir"],
                text=True,
            ).strip()
          except Exception:
            cache_dir = None

          Path(cache_dir or Path("~/.cache/pip").expanduser()).expanduser().mkdir(
              parents=True,
              exist_ok=True,
          )
          PY
      - uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
        with:
          # Use 3.11 to align with available CPU-only PyTorch wheels on macOS
          python-version: '3.11'
          architecture: 'x64'
          cache: pip
          cache-dependency-path: 'requirements.lock'
      - name: Verify $AGIALPHA configuration
        run: python scripts/check_agialpha_config.py
      - name: Install dependencies  # use CPU-only lock file on macOS
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-demo-cpu.lock
          pip install -r requirements-dev.lock
      - name: Install macOS extras
        run: pip install appnope==0.1.4
      - uses: actions/setup-node@2028fbc5c25fe9cf00d9f06a71cc4710d4507903 # v6.0.0
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'
          cache-dependency-path: ${{ env.NODE_LOCKFILES }}
      - name: Configure npm
        run: |
          npm config set fund false
          npm config set audit false
      - name: Show tool versions
        shell: bash
        run: |
          set -euo pipefail
          python --version
          node --version
          git --version
          if command -v docker >/dev/null 2>&1; then
            docker --version
            docker compose version || docker-compose version
          else
            echo "::notice::Docker not available on macos-latest runner"
          fi
      - name: Verify environment
        run: |
          python scripts/check_python_deps.py
          python check_env.py --auto-install
      - uses: ./.github/actions/setup-insight-assets
      - name: Build web assets
        shell: bash
        run: |
          set -e
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          npm ci --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
          (cd alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 && \
            npx update-browserslist-db --update-db --yes)
          npm run --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 build
      - name: Run smoke tests
        run: pytest -m smoke -q

  docs-check:
    name: "üìú MkDocs"
    if: ${{ always() && needs.owner-check.result == 'success' }}
    needs: owner-check
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      SANDBOX_IMAGE: selfheal-sandbox:latest
      PWA_TIMEOUT_MS: '120000'
      NPM_CONFIG_CACHE: ${{ github.workspace }}/.npm-cache/docs-check
      NPM_CONFIG_FUND: 'false'
      NPM_CONFIG_AUDIT: 'false'
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: Check for binary diffs (pre-build)
        run: python scripts/check_no_binary_diff.py
      - name: Ensure pip cache directory
        shell: bash
        run: |
          python - <<'PY'
          import subprocess
          import sys
          from pathlib import Path

          try:
            cache_dir = subprocess.check_output(
                [sys.executable, "-m", "pip", "cache", "dir"],
                text=True,
            ).strip()
          except Exception:
            cache_dir = None

          Path(cache_dir or Path("~/.cache/pip").expanduser()).expanduser().mkdir(
              parents=True,
              exist_ok=True,
          )
          PY
      - uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
        with:
          # Stay on 3.12 until upstream publishes stable PyTorch wheels for 3.13
          # to avoid CI flakiness during docs builds.
          python-version: '3.12'
          cache: pip
          cache-dependency-path: 'requirements.lock'
      - name: Free disk space
        run: bash scripts/ci_free_disk.sh
      - name: Verify $AGIALPHA configuration
        run: python scripts/check_agialpha_config.py
      - name: Cache pre-commit
        uses: actions/cache@v5.0.2 # 8b402f58fbc84540c8b491a91e594a4576fec3d7
        with:
          path: .cache/pre-commit
          key: ${{ runner.os }}-precommit-${{ hashFiles('.pre-commit-config.yaml') }}
      - name: Cache Playwright browsers
        uses: actions/cache@v5.0.2 # 8b402f58fbc84540c8b491a91e594a4576fec3d7
        with:
          path: ${{ env.PLAYWRIGHT_BROWSERS_PATH }}
          key: ${{ runner.os }}-playwright-${{ hashFiles('alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-
      - name: Install docs requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-docs.lock
      - name: Install base dependencies
        run: python check_env.py --auto-install
      - uses: ./.github/actions/setup-insight-assets
      - uses: actions/setup-node@2028fbc5c25fe9cf00d9f06a71cc4710d4507903 # v6.0.0
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'
          cache-dependency-path: ${{ env.NODE_LOCKFILES }}
      - name: Configure npm
        run: |
          npm config set fund false
          npm config set audit false
      - uses: ./.github/actions/setup-env
        with:
          sandbox-image: ${{ env.SANDBOX_IMAGE }}
        env:
          SANDBOX_IMAGE: ${{ env.SANDBOX_IMAGE || 'selfheal-sandbox:latest' }}
      - name: Install insight browser dependencies
        run: |
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          npm ci --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
      - name: Build insight browser
        run: npm --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 run build
      # asset fetching handled by setup-insight-assets
      - name: Install pre-commit
        run: pip install pre-commit==4.2.0
        env:
          PRE_COMMIT_HOME: .cache/pre-commit
      - name: Lint docs with pre-commit
        run: git ls-files -z 'docs/**' | xargs -0 pre-commit run --files
        env:
          PRE_COMMIT_HOME: .cache/pre-commit
          SKIP: eslint-insight-browser
      - name: Build documentation
        run: mkdocs build --strict
      - name: Check for binary diffs (post-build)
        run: python scripts/check_no_binary_diff.py

  docs-build:
    name: "üìö Docs Build"
    if: ${{ always() && needs.owner-check.result == 'success' }}
    needs: owner-check
    runs-on: ubuntu-latest
    timeout-minutes: 45
    permissions:
      pull-requests: write
    env:
      FETCH_ASSETS_ATTEMPTS: '5'
      SANDBOX_IMAGE: selfheal-sandbox:latest
      PWA_TIMEOUT_MS: '120000'
      NPM_CONFIG_CACHE: ${{ github.workspace }}/.npm-cache/docs-build
      NPM_CONFIG_FUND: 'false'
      NPM_CONFIG_AUDIT: 'false'
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: Check for binary diffs (pre-build)
        run: python scripts/check_no_binary_diff.py
      - name: Ensure pip cache directory
        shell: bash
        run: |
          python - <<'PY'
          import subprocess
          import sys
          from pathlib import Path

          try:
            cache_dir = subprocess.check_output(
                [sys.executable, "-m", "pip", "cache", "dir"],
                text=True,
            ).strip()
          except Exception:
            cache_dir = None

          Path(cache_dir or Path("~/.cache/pip").expanduser()).expanduser().mkdir(
              parents=True,
              exist_ok=True,
          )
          PY
      - uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
        with:
          # Keep parity with supported test matrix (3.11‚Äì3.12) so doc builds do not
          # pull unsupported wheels.
          python-version: '3.12'
          cache: pip
          cache-dependency-path: 'requirements.lock'
      - name: Free disk space
        run: bash scripts/ci_free_disk.sh
      - name: Verify $AGIALPHA configuration
        run: python scripts/check_agialpha_config.py
      - name: Cache pre-commit
        uses: actions/cache@v5.0.2 # 8b402f58fbc84540c8b491a91e594a4576fec3d7
        with:
          path: .cache/pre-commit
          key: ${{ runner.os }}-precommit-${{ hashFiles('.pre-commit-config.yaml') }}
      - uses: actions/setup-node@2028fbc5c25fe9cf00d9f06a71cc4710d4507903 # v6.0.0
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'
          cache-dependency-path: ${{ env.NODE_LOCKFILES }}
      - name: Configure npm
        run: |
          npm config set fund false
          npm config set audit false
      - uses: ./.github/actions/setup-env
        with:
          sandbox-image: ${{ env.SANDBOX_IMAGE }}
        env:
          SANDBOX_IMAGE: ${{ env.SANDBOX_IMAGE || 'selfheal-sandbox:latest' }}
      - name: Install base dependencies
        run: python check_env.py --auto-install
      - name: Install docs requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-docs.lock
      - name: Install insight browser dependencies
        run: |
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          npm ci --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
      - name: Install web client dependencies
        run: |
          rm -rf alpha_factory_v1/core/interface/web_client/node_modules
          npm ci --prefix alpha_factory_v1/core/interface/web_client
      - name: Build web client
        run: make build_web
      - name: Update browserslist database (Insight demo)
        working-directory: alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
        run: npx update-browserslist-db --update-db --yes
      - name: Update browserslist database (Web client)
        working-directory: alpha_factory_v1/core/interface/web_client
        run: npx update-browserslist-db --update-db --yes
      - name: Install pre-commit
        run: pip install pre-commit==4.2.0
        env:
          PRE_COMMIT_HOME: .cache/pre-commit
      - name: Lint docs with pre-commit
        run: git ls-files -z 'docs/**' | xargs -0 pre-commit run --files
        env:
          PRE_COMMIT_HOME: .cache/pre-commit
          SKIP: eslint-insight-browser
      - name: Build insight browser
        run: npm --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 run build
      - name: Build gallery site
        run: ./scripts/build_gallery_site.sh
      - name: Reclaim disk before Playwright
        run: |
          set -euo pipefail
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          rm -rf alpha_factory_v1/core/interface/web_client/node_modules
          rm -rf "$NPM_CONFIG_CACHE"
          rm -rf .cache/pre-commit
          rm -rf ~/.cache/pip ~/.cache/pypoetry ~/.cache/node-gyp
          df -h
      - uses: ./.github/actions/setup-insight-assets
      - name: Check Insight SRI
        run: python scripts/check_insight_sri.py docs/alpha_agi_insight_v1
      - name: Detect Pyodide changes
        id: pyodide-diff-docs
        run: |
          if git diff --quiet; then
            echo "changed=false" >> "$GITHUB_OUTPUT"
          else
            echo "changed=true" >> "$GITHUB_OUTPUT"
          fi
      - name: Cache Playwright browsers
        uses: actions/cache@v5.0.2 # 8b402f58fbc84540c8b491a91e594a4576fec3d7
        with:
          path: ${{ env.PLAYWRIGHT_BROWSERS_PATH }}
          key: ${{ runner.os }}-playwright-${{ hashFiles('alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-playwright-
      - name: Install Playwright system dependencies (Python)
        run: python -m playwright install-deps chromium
      - name: Install Playwright browsers (Python)
        run: python -m playwright install chromium
      - name: Install Playwright browsers (Node)
        run: npx playwright install
      - name: Verify demo pages
        run: python scripts/verify_demo_pages.py
      - name: Verify Insight PWA offline
        run: |
          python -m http.server --directory site 8000 &
          SERVER_PID=$!
          sleep 2
          python scripts/verify_insight_offline.py
          kill "$SERVER_PID"
      - name: Check for binary diffs (post-build)
        run: python scripts/check_no_binary_diff.py

  docker:
    name: "üê≥ Docker build"
    if: ${{ always() && needs.owner-check.result == 'success' }}
    needs: owner-check
    runs-on: ubuntu-latest
    timeout-minutes: 45
    permissions:
      # `contents` enables checkout, `packages` allows GHCR pushes, and `id-token`
      # is required for keyless cosign signatures.
      contents: read
      packages: write
      id-token: write
    env:
      NPM_CONFIG_CACHE: ${{ github.workspace }}/.npm-cache/docker
      NPM_CONFIG_FUND: 'false'
      NPM_CONFIG_AUDIT: 'false'
    # This job builds and pushes the image.
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: Free disk space
        run: bash scripts/ci_free_disk.sh
      - name: Ensure pip cache directory
        shell: bash
        run: |
          python - <<'PY'
          import subprocess
          import sys
          from pathlib import Path

          try:
            cache_dir = subprocess.check_output(
                [sys.executable, "-m", "pip", "cache", "dir"],
                text=True,
            ).strip()
          except Exception:
            cache_dir = None

          Path(cache_dir or Path("~/.cache/pip").expanduser()).expanduser().mkdir(
              parents=True,
              exist_ok=True,
          )
          PY
      - uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
        with:
          # Align build Python with supported runtime versions to keep dependency
          # resolution stable while PyTorch finalizes 3.13 wheels.
          python-version: '3.12'
          cache: pip
          cache-dependency-path: 'requirements.lock'
      - name: Verify $AGIALPHA configuration
        run: python scripts/check_agialpha_config.py
      - name: Export repo_owner_lower
        run: echo "repo_owner_lower=${{ needs.owner-check.outputs.repo_owner_lower }}" >> "$GITHUB_ENV"
      - uses: actions/setup-node@2028fbc5c25fe9cf00d9f06a71cc4710d4507903 # v6.0.0
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'
          cache-dependency-path: ${{ env.NODE_LOCKFILES }}
      - name: Configure npm
        run: |
          npm config set fund false
          npm config set audit false
      - uses: ./.github/actions/setup-env
        with:
          sandbox-image: ${{ env.SANDBOX_IMAGE }}
        env:
          SANDBOX_IMAGE: ${{ env.SANDBOX_IMAGE || 'selfheal-sandbox:latest' }}
      - name: Install insight browser dependencies
        run: |
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          npm ci --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
      - name: Update browserslist database (Insight demo)
        working-directory: alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1
        run: npx update-browserslist-db --update-db --yes
      - name: Install web client dependencies
        run: |
          rm -rf alpha_factory_v1/core/interface/web_client/node_modules
          npm ci --prefix alpha_factory_v1/core/interface/web_client
      - name: Update browserslist database (Web client)
        working-directory: alpha_factory_v1/core/interface/web_client
        run: npx update-browserslist-db --update-db --yes
      - uses: ./.github/actions/setup-insight-assets
      - name: Audit insight browser dependencies
        # Keep the audit gate strict on critical CVEs while avoiding flaky failures
        # from transient high/medium advisories that Dependabot already reports.
        run: npm --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 audit --production --audit-level=critical
      - name: Run insight browser tests
        env:
          CI: 'true'
        run: npm --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 test
      - name: Type check insight browser
        run: npm --prefix alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1 run typecheck
      - name: Build web client
        run: |
          make build_web
          test -f alpha_factory_v1/core/interface/web_client/dist/index.html
      - name: Archive web client dist
        run: |
          tar -czf web-client.tar.gz -C alpha_factory_v1/core/interface/web_client/dist .
          sha256sum web-client.tar.gz > web-client.sha256
      - name: Install cosign
        uses: sigstore/cosign-installer@v4.0.0 # faadad0cce49287aee09b3a48701e75088a2c6ad
        with:
          cosign-release: 'v2.5.3'
      - name: Sign web client artifact
        run: |
          cosign sign-blob --yes \
            --output-signature web-client.tar.gz.sig \
            --output-certificate web-client.tar.gz.pem \
            --bundle web-client.tar.gz.bundle \
            web-client.tar.gz
      - name: Verify web client signature
        run: |
          cosign verify-blob \
            --certificate-identity-regexp "$COSIGN_CERT_IDENTITY_REGEX" \
            --certificate-oidc-issuer "$COSIGN_CERT_ISSUER" \
            --signature web-client.tar.gz.sig \
            --certificate web-client.tar.gz.pem \
            web-client.tar.gz
      - name: Check web client artifact
        id: web-client-check
        run: |
          if [[ -f web-client.tar.gz ]]; then echo "found=true" >> "$GITHUB_OUTPUT"; fi
      - uses: actions/upload-artifact@v6.0.0 # b7c566a772e6b6bfb58ed0dc250532a479d7789f
        if: steps.web-client-check.outputs.found == 'true'
        with:
          name: web-client
          path: |
            web-client.tar.gz
            web-client.sha256
            web-client.tar.gz.sig
            web-client.tar.gz.pem
            web-client.tar.gz.bundle
      - name: Ensure Chrome for Axe
        run: |
          set -euo pipefail

          find_chrome() {
            for candidate in \ \
              google-chrome-stable \ \
              google-chrome \ \
              chromium-browser \ \
              chromium \ \
              /snap/bin/chromium; do
              if command -v "$candidate" >/dev/null 2>&1; then
                command -v "$candidate"
                return
              elif [ -x "$candidate" ]; then
                echo "$candidate"
                return
              fi
            done
          }

          chrome_bin=$(find_chrome || true)

          if [ -z "$chrome_bin" ]; then
            export DEBIAN_FRONTEND=noninteractive
            sudo apt-get update
            if ! sudo apt-get install -y chromium-browser chromium-chromedriver; then
              echo "::warning::'chromium-browser' package unavailable; trying 'chromium'."
              sudo apt-get install -y chromium chromium-driver || true
            fi
            chrome_bin=$(find_chrome || true)
          fi

          if [ -z "$chrome_bin" ]; then
            echo "::error::Chrome binary not found for Axe audit"
            exit 1
          fi

          echo "CHROME_BIN=$chrome_bin" >> "$GITHUB_ENV"
          if command -v chromedriver >/dev/null 2>&1; then
            echo "CHROMEDRIVER_PATH=$(command -v chromedriver)" >> "$GITHUB_ENV"
          fi
      - name: Accessibility audit
        run: |
          set -euo pipefail
          npx --yes @axe-core/cli \
            --stdout \
            --chrome-path "${CHROME_BIN:-google-chrome-stable}" \
            ${CHROMEDRIVER_PATH:+--chromedriver-path "$CHROMEDRIVER_PATH"} \
            "file://${{ github.workspace }}/alpha_factory_v1/core/interface/web_client/dist/index.html" \
            > axe.json
          score=$(python scripts/axe_score.py axe.json)
          echo "a11y score: $score (threshold $A11Y_THRESHOLD)"
          if [ "$score" -lt "$A11Y_THRESHOLD" ]; then
            cat axe.json
            exit 1
          fi
      - name: Reclaim disk before Docker build
        run: |
          set -euo pipefail
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1/node_modules
          rm -rf alpha_factory_v1/core/interface/web_client/node_modules
          rm -rf alpha_factory_v1/core/interface/web_client/staking/node_modules
          rm -rf alpha_factory_v1/demos/alpha_agi_insight_v1/src/interface/web_client/node_modules
          rm -rf ~/.cache/ms-playwright || true
      - name: Build image
        run: |
          docker build -t "$DOCKER_IMAGE:ci" \
            -f infrastructure/Dockerfile \
            .
      - name: Smoke test image
        run: |
          docker run --rm -e RUN_MODE=cli "$DOCKER_IMAGE:ci" simulate --horizon 1 --offline
      - name: Login to GHCR
        if: github.event_name != 'pull_request' && github.event_name != 'merge_group'
        uses: docker/login-action@v3.6.0 # 5e57cd118135c172c3672efd75eb46360885c0ef
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      - name: Push image
        if: github.event_name != 'pull_request' && github.event_name != 'merge_group'
        run: |
          docker tag "$DOCKER_IMAGE:ci" "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.sha }}"
          docker push "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.sha }}"
      - name: Install cosign
        if: github.event_name != 'pull_request' && github.event_name != 'merge_group'
        uses: sigstore/cosign-installer@v4.0.0 # faadad0cce49287aee09b3a48701e75088a2c6ad
        with:
          cosign-release: 'v2.5.3'
      - name: Sign image
        if: github.event_name != 'pull_request' && github.event_name != 'merge_group'
        run: cosign sign --yes "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.sha }}"
      - name: Verify image signature
        if: github.event_name != 'pull_request' && github.event_name != 'merge_group'
        run: cosign verify "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.sha }}"

  deploy:
    name: "üì¶ Deploy"
    if: ${{ needs.owner-check.result == 'success' && startsWith(github.ref, 'refs/tags/') }}
    needs: [owner-check, workflow-lint, lint-type, insight-eslint, tests, windows-smoke, macos-smoke, docs-check, docs-build, docker]
    runs-on: ubuntu-latest
    timeout-minutes: 45
    permissions:
      contents: write
      packages: write
      id-token: write
    environment: ci-on-demand
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - name: Export repo_owner_lower
        run: echo "repo_owner_lower=${{ needs.owner-check.outputs.repo_owner_lower }}" >> "$GITHUB_ENV"
      - name: Show tool versions
        run: |
          python --version
          node --version
          docker --version
          docker compose version
          git --version
      - name: Login to GHCR
        uses: docker/login-action@v3.6.0 # 5e57cd118135c172c3672efd75eb46360885c0ef
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      - name: Install cosign
        uses: sigstore/cosign-installer@v4.0.0 # faadad0cce49287aee09b3a48701e75088a2c6ad
        with:
          cosign-release: 'v2.5.3'
      - name: Pull previous image
        run: docker pull "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:latest" || true
      - name: Tag previous
        run: docker tag "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:latest" "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:previous" || true
      - name: Push previous tag
        run: docker push "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:previous" || true
      - name: Pull release image
        run: docker pull "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.sha }}"
      - name: Tag and push new image
        run: |
          docker tag "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.sha }}" "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.ref_name }}"
          docker tag "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.sha }}" "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:latest"
          docker push "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.ref_name }}"
          docker push "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:latest"
      - name: Sign release images
        run: |
          cosign sign --yes "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.ref_name }}"
          cosign sign --yes "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:latest"
      - name: Verify release signatures
        run: |
          cosign verify "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:${{ github.ref_name }}"
          cosign verify "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:latest"
      - uses: actions/download-artifact@018cc2cf5baa6db3ef3c5f8a56943fffe632ef53 # v6.0.0
        with:
          name: web-client
      - name: Verify web client artifact
        run: sha256sum -c web-client.sha256
      - name: Verify web client signature
        run: |
          cosign verify-blob \
            --certificate-identity-regexp "$COSIGN_CERT_IDENTITY_REGEX" \
            --certificate-oidc-issuer "$COSIGN_CERT_ISSUER" \
            --signature web-client.tar.gz.sig \
            --certificate web-client.tar.gz.pem \
            web-client.tar.gz
      - name: Prepare release assets
        run: echo "Using prebuilt web client artifact"
      - name: Upload release assets
        uses: softprops/action-gh-release@v2.5.0 # a06a81a03ee405af7f2048a818ed3f03bbf83c7b
        with:
          files: web-client.tar.gz
      - name: Rollback on failure
        if: failure()
        run: |
          echo "Rolling back to previous image"
          docker pull "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:previous"
          docker tag "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:previous" "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:latest"
          docker push "ghcr.io/$repo_owner_lower/$DOCKER_IMAGE:latest"
          echo "Rollback succeeded"

  branch-protection:
    name: "üîí Branch protection guardrails"
    if: ${{ needs.owner-check.result == 'success' && (github.ref == 'refs/heads/main' || github.event_name == 'merge_group' || (github.event_name == 'pull_request' && github.event.pull_request.base.ref == 'main')) }}
    needs: [owner-check, workflow-lint, lint-type, insight-eslint, tests, windows-smoke, macos-smoke, docs-check, docs-build, docker]
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
      - uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
        with:
          python-version: '3.12'
      - name: Verify $AGIALPHA configuration
        run: python scripts/check_agialpha_config.py
      - name: Verify branch protection on main
        env:
          # Prefer a repository admin token so the job can enforce missing
          # protection rules. Fall back to the default GITHUB_TOKEN for
          # read-only verification when the admin secret is unavailable so PRs
          # from forks do not fail outright.
          ADMIN_GITHUB_TOKEN: ${{ secrets.ADMIN_GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.ADMIN_GITHUB_TOKEN != '' && secrets.ADMIN_GITHUB_TOKEN || github.token }}
          TARGET_BRANCH: ${{ github.event_name == 'pull_request' && github.event.pull_request.base.ref || 'main' }}
        run: |
          apply_flag=""
          warn_flag=""
          if [ -n "${ADMIN_GITHUB_TOKEN}" ]; then
            apply_flag="--apply"
          else
            echo "::notice::ADMIN_GITHUB_TOKEN not set; running read-only branch protection check with default token."
            warn_flag="--warn-only"
          fi

          python scripts/verify_branch_protection.py \
            --branch "${TARGET_BRANCH}" \
            ${apply_flag} \
            ${warn_flag} \
            --required-checks-file scripts/required_checks.json
