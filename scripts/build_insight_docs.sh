#!/usr/bin/env bash
# SPDX-License-Identifier: Apache-2.0
# Build the Insight demo and documentation.
# Existing files under $DOCS_DIR that are not generated by the browser build
# are copied aside before the directory is wiped. After unzipping the new
# bundle, those files are restored so manual assets like images or PDFs survive
# across rebuilds.
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
cd "$REPO_ROOT"

BROWSER_DIR="alpha_factory_v1/demos/alpha_agi_insight_v1/insight_browser_v1"
DOCS_DIR="docs/alpha_agi_insight_v1"

usage() {
    cat <<USAGE
Usage: $0

Build the Insight browser bundle, refresh $DOCS_DIR
and generate the mkdocs site.
USAGE
}

if [[ "${1:-}" =~ ^(-h|--help)$ ]]; then
    usage
    exit 0
fi

# Ensure the correct Node.js version before running npm
if ! node "$BROWSER_DIR/build/version_check.js"; then
    echo "ERROR: Node.js 22+ is required to build the Insight docs." >&2
    exit 1
fi

# Fetch WASM assets then install Node dependencies and build the browser bundle
npm --prefix "$BROWSER_DIR" run fetch-assets
npm --prefix "$BROWSER_DIR" ci
(cd "$BROWSER_DIR" && npx update-browserslist-db --update-db --yes)
npm --prefix "$BROWSER_DIR" run build:dist

# Refresh docs directory with the new bundle while preserving existing binaries.
DOCS_TMP="$(mktemp -d)"
BINARY_EXCLUDES=(
    "*.wasm"
    "*.zip"
    "*.gz"
    "*.png"
    "*.jpg"
    "*.jpeg"
    "*.webp"
    "*.gif"
    "*.pdf"
    "*.ico"
    "*.mp3"
    "*.mp4"
    "*.woff"
    "*.woff2"
    "*.ttf"
    "*.otf"
    "*.bin"
    "*.exe"
    "*.dll"
    "*.so"
    "*.dylib"
    "assets/wasm/*"
    "assets/wasm_llm/*"
    "assets/pyodide/*"
)
unzip -q -o "$BROWSER_DIR/insight_browser.zip" -d "$DOCS_TMP" -x "${BINARY_EXCLUDES[@]}"
# Ensure the bundle script tag includes the correct hashes after extraction
python scripts/ensure_insight_sri.py "$DOCS_TMP"
# Ensure the service worker and PWA files exist in the docs directory
unzip -q -j -o "$BROWSER_DIR/insight_browser.zip" service-worker.js -d "$DOCS_TMP" || true
unzip -q -j -o "$BROWSER_DIR/insight_browser.zip" assets/manifest.json -d "$DOCS_TMP" || true
mkdir -p "$DOCS_TMP/assets/lib"
unzip -q -j -o "$BROWSER_DIR/insight_browser.zip" assets/lib/workbox-sw.js -d "$DOCS_TMP/assets/lib" || true
python scripts/ensure_insight_sw_hash.py "$DOCS_TMP"
python scripts/ensure_insight_csp.py "$DOCS_TMP"

mkdir -p "$DOCS_DIR"
rsync -a --delete \
    --exclude="*.wasm" \
    --exclude="*.zip" \
    --exclude="*.gz" \
    --exclude="*.png" \
    --exclude="*.jpg" \
    --exclude="*.jpeg" \
    --exclude="*.webp" \
    --exclude="*.gif" \
    --exclude="*.pdf" \
    --exclude="*.ico" \
    --exclude="*.mp3" \
    --exclude="*.mp4" \
    --exclude="*.woff" \
    --exclude="*.woff2" \
    --exclude="*.ttf" \
    --exclude="*.otf" \
    --exclude="*.bin" \
    --exclude="*.exe" \
    --exclude="*.dll" \
    --exclude="*.so" \
    --exclude="*.dylib" \
    --exclude="assets/wasm/" \
    --exclude="assets/wasm_llm/" \
    --exclude="assets/pyodide/" \
    --exclude="plotly.min.js.LICENSE.txt" \
    "$DOCS_TMP"/ "$DOCS_DIR"/
rm -rf "$DOCS_TMP"

LICENSE_FILE="plotly.min.js.LICENSE.txt"
if [[ ! -f "$DOCS_DIR/$LICENSE_FILE" && -f "$REPO_ROOT/docs/alpha_agi_insight_v1/$LICENSE_FILE" ]]; then
    cp -a "$REPO_ROOT/docs/alpha_agi_insight_v1/$LICENSE_FILE" "$DOCS_DIR/"
fi

# Ensure the favicon survives extraction
ICON_FILE="favicon.svg"
if [[ ! -f "$DOCS_DIR/$ICON_FILE" && -f "$BROWSER_DIR/$ICON_FILE" ]]; then
    cp -a "$BROWSER_DIR/$ICON_FILE" "$DOCS_DIR/"
fi

# Export the latest meta-agent tree when lineage data is available
TREE_INPUT="lineage/run.jsonl"
TREE_OUTPUT="$DOCS_DIR/tree.json"
if [[ -f "$TREE_INPUT" ]]; then
    python alpha_factory_v1/demos/alpha_agi_insight_v1/tools/export_tree.py \
        "$TREE_INPUT" -o "$TREE_OUTPUT"
else
    echo "WARNING: $TREE_INPUT not found; skipping tree export" >&2
fi

# Validate the bundled workbox file before generating docs
if ! python scripts/verify_workbox_hash.py "$DOCS_DIR"; then
    echo "ERROR: Workbox hash verification failed" >&2
    exit 1
fi

# Copy static assets from other demos so MkDocs can serve them
copy_assets() {
    mkdir -p docs/aiga_meta_evolution/assets
    cp alpha_factory_v1/demos/aiga_meta_evolution/bridge_overview.svg \
        docs/aiga_meta_evolution/assets/bridge_overview.svg
    for demo in meta_agentic_agi meta_agentic_agi_v2 meta_agentic_agi_v3; do
        src="alpha_factory_v1/demos/$demo/ui/assets"
        dest="docs/$demo/assets"
        mkdir -p "$dest"
        cp -a "$src"/* "$dest/"
    done

    # Verify the Pyodide runtime files for the gallery are already present.
    pyodide_dest="docs/assets/pyodide"
    if [[ ! -f "$pyodide_dest/pyodide.asm.wasm" || ! -f "$pyodide_dest/pyodide.js" ]]; then
        echo "WARNING: Pyodide assets missing from $pyodide_dest. Skipping binary refresh." >&2
    fi
}
copy_assets

# Regenerate Markdown pages for each demo from their README files
python scripts/generate_demo_docs.py
python scripts/generate_gallery_html.py

# Build the MkDocs site. Strict mode is always enabled so any warnings
# surface as errors both locally and in CI.
mkdocs build --strict

# Verify the Workbox hash again in the generated site directory
if ! python scripts/verify_workbox_hash.py site/alpha_agi_insight_v1; then
    echo "ERROR: Workbox hash verification failed for generated site" >&2
    exit 1
fi
