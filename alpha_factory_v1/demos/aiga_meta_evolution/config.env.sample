# ╔══════════════════════════════════════════════════════════════════════╗
# ║  AI‑GA Meta‑Evolution – sample configuration                         ║
# ║  Copy to config.env and adjust as needed. Any missing variable will  ║
# ║  fall back to the image's sane defaults.                             ║
# ╚══════════════════════════════════════════════════════════════════════╝

# ─── Core LLM settings ──────────────────────────────────────────────────
# Leave OPENAI_API_KEY blank to run 100 % offline (Ollama fallback).
OPENAI_API_KEY=
MODEL_NAME="gpt-4o-mini"          # any model supported by OpenAI Agents SDK
TEMPERATURE=0.35                  # 0–2.0, higher → more creative

# ─── Offline LLM fallback (Ollama) ───────────────────────────────────────
OLLAMA_BASE_URL="http://ollama:11434/v1"

# ─── Service identity & ports ────────────────────────────────────────────
SERVICE_NAME="aiga-meta-evolution"
GRADIO_PORT=7862
API_PORT=8000

# ─── Persistence & scaling rails ────────────────────────────────────────
CHECKPOINT_DIR="/data/checkpoints"
MAX_GEN=1000          # safety upper‑bound per /evolve request

# ─── Logging / Observability ────────────────────────────────────────────
LOG_LEVEL="INFO"      # DEBUG | INFO | WARNING | ERROR
ENABLE_OTEL=false      # true enables OpenTelemetry auto‑instrumentation
OTEL_EXPORTER_OTLP_ENDPOINT="http://otel-collector:4318"
# Prometheus scrape path is /metrics (no env required)

# ─── Optional trade adapter secrets ─────────────────────────────────────
BROKER_API_KEY=
POLYGON_API_KEY=
