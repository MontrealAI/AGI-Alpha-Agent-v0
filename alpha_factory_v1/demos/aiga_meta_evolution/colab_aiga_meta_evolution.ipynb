{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3a7a5e",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "This repository is a conceptual research prototype. References to \"AGI\" and \"superintelligence\" describe aspirational goals and do not indicate the presence of a real general intelligence. Use at your own risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e7483a",
   "metadata": {},
   "source": [
    "# \ud83e\uddec AI-GA Meta-Evolution \u00b7 Colab\n",
    "\n",
    "Fully-featured notebook that spins up the **three-pillar** demo from Clune (2020) in ~2 minutes.\n",
    "\n",
    "**What you get**\n",
    "1. \ud83d\udce6 Minimal runtime install (CPU \u2b05\ufe0f default, GPU optional)\n",
    "2. \ud83d\udd11 Optional `OPENAI_API_KEY` for LLM commentary (offline Mixtral otherwise)\n",
    "3. \ud83d\ude80 `agent_aiga_entrypoint.py` exposing:\n",
    "   * Gradio dashboard \u2192 port `7862` (public HTTPS link auto-printed)\n",
    "   * FastAPI JSON API \u2192 port `8000` (see `/docs`)\n",
    "4. \ud83e\uddea Unit-test cell (`pytest -q`) \u2013 target **\u2265 90 % branch coverage** < 0.5 s\n",
    "5. \ud83d\udcc8 Inline Prometheus scrape & Matplotlib plot\n",
    "6. \ud83e\udd16 Example REST calls (evolve / checkpoint) using `httpx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab1af1",
   "metadata": {
    "id": "00_gpu_flag"
   },
   "outputs": [],
   "source": [
    "#@title \u21b3 Choose runtime {display-mode: \"form\"}\n",
    "USE_GPU = False  #@param {type:\"boolean\"}\n",
    "print(\"\u2699\ufe0f  GPU runtime\" if USE_GPU else \"\u2699\ufe0f  CPU runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dcf6fb",
   "metadata": {
    "id": "01_setup"
   },
   "outputs": [],
   "source": [
    "# \u21b3 Setup (\u224890 s CPU / 60 s GPU) -----------------------------------------\n",
    "%%bash --no-stderr\n",
    "set -Eeuo pipefail\n",
    "\n",
    "# clone\n",
    "if [[ ! -d AGI-Alpha-Agent-v0 ]]; then\n",
    "  echo \"\ud83d\udce1  Cloning Alpha-Factory repo \u2026\" >&2\n",
    "  git clone --depth 1 https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git -q\n",
    "fi\n",
    "cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/aiga_meta_evolution\n",
    "\n",
    "# wheel index depending on GPU flag\n",
    "WHL_URL=\"https://download.pytorch.org/whl/$(python - <<PY\n",
    "import os; print('cu118' if os.environ.get('USE_GPU','False')=='True' else 'cpu')\n",
    "PY)\"\n",
    "\n",
    "echo \"\ud83d\udce6  Installing deps \u2026\" >&2\n",
    "pip -q install --upgrade pip\n",
    "pip -q install torch torchvision --extra-index-url $WHL_URL\n",
    "pip -q install gymnasium[classic_control] gradio==4.* openai_agents httpx prometheus-client pytest coverage scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \u2b06\ufe0f Upload a wheelhouse (optional)\n",
    "Use the file browser on the left to upload a `wheels.zip` archive. Unzip it\n",
    "and point `check_env.py` at the extracted directory:\n",
    "```bash\n",
    "WHEELHOUSE=/content/wheels\n",
    "unzip -q wheels.zip -d \"$WHEELHOUSE\"\n",
    "python AGI-Alpha-Agent-v0/check_env.py --auto-install --wheelhouse \"$WHEELHOUSE\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aec4cc",
   "metadata": {
    "id": "02_key"
   },
   "outputs": [],
   "source": [
    "# \u21b3 (optional) supply OpenAI key ------------------------------------------\n",
    "import os, getpass\n",
    "\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    key = getpass.getpass('Paste OPENAI_API_KEY, or press Enter for offline mode: ')\n",
    "    if key:\n",
    "        %env OPENAI_API_KEY=$key\n",
    "        print('\ud83d\udd11  Key set \u2013 online mode.')\n",
    "    else:\n",
    "        print('\ud83d\udef0  Offline mode \u2013 Mixtral fallback.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f17a4d",
   "metadata": {
    "id": "03_tests"
   },
   "outputs": [],
   "source": [
    "# \u21b3 Quick unit tests ------------------------------------------------------\n",
    "%%bash\n",
    "cd AGI-Alpha-Agent-v0/alpha_factory_v1/demos/aiga_meta_evolution\n",
    "pytest -q || echo '\u26a0\ufe0f tests failed (safe to ignore for demo)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e615c61",
   "metadata": {
    "id": "04_launch"
   },
   "outputs": [],
   "source": [
    "# \u21b3 Launch the orchestration service & dashboard --------------------------\n",
    "import subprocess, threading, re, time, sys, pathlib, os, json\n",
    "\n",
    "ROOT = pathlib.Path(\"AGI-Alpha-Agent-v0/alpha_factory_v1/demos/aiga_meta_evolution\").resolve()\n",
    "os.chdir(ROOT)\n",
    "\n",
    "proc = subprocess.Popen([sys.executable, \"agent_aiga_entrypoint.py\"],\n",
    "                        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "                        text=True)\n",
    "\n",
    "public = None\n",
    "def _tail():\n",
    "    global public\n",
    "    for line in proc.stdout:\n",
    "        print(line, end=\"\")\n",
    "        if not public and \"Running on\" in line and \"https\" in line:\n",
    "            public = re.search(r\"https?://[\\w./-]+\", line)[0]\n",
    "            print(f\"\\n\ud83d\udd17  Dashboard \u2192 {public}\\n\")\n",
    "threading.Thread(target=_tail, daemon=True).start()\n",
    "\n",
    "for _ in range(90):\n",
    "    if public: break\n",
    "    time.sleep(1)\n",
    "if not public:\n",
    "    print(\"\u23f3  Still starting \u2026 open logs above for status.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345c52b",
   "metadata": {},
   "source": [
    "## \u260e\ufe0f API interactions\n",
    "Below we hit the running FastAPI service using `httpx`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172d6d7",
   "metadata": {
    "id": "05_api"
   },
   "outputs": [],
   "source": [
    "import httpx, time, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "API = \"http://localhost:8000\"\n",
    "print(httpx.get(API + \"/health\").json())\n",
    "\n",
    "# schedule 20 generations asynchronously\n",
    "httpx.post(API + \"/evolve/20\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f6544e",
   "metadata": {
    "id": "06_metrics"
   },
   "outputs": [],
   "source": [
    "# \u21b3 scrape Prometheus metrics & plot --------------------------------------\n",
    "import re, json, pandas as pd, matplotlib.pyplot as plt, httpx, time\n",
    "\n",
    "raw = httpx.get(API + \"/metrics\").text\n",
    "fitness = float(re.search(r\"aiga_best_fitness (\\d+\\.?\\d*)\", raw).group(1))\n",
    "gen     = int(re.search(r\"aiga_generations_total (\\d+)\", raw).group(1))\n",
    "print(f\"Generation {gen}, best fitness {fitness:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64fbbbe",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Plot fitness history\n",
    "The checkpoint JSON embeds the `(generation, avg_fitness)` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00decf4e",
   "metadata": {
    "id": "07_plot"
   },
   "outputs": [],
   "source": [
    "import json, pathlib, matplotlib.pyplot as plt, pandas as pd, glob\n",
    "ckpt = sorted(glob.glob(\"checkpoints/evolver_gen*.json\"))[-1]\n",
    "hist = json.loads(pathlib.Path(ckpt).read_text())[\"history\"]\n",
    "df = pd.DataFrame(hist, columns=[\"gen\", \"avg\"])\n",
    "df.plot(x=\"gen\", y=\"avg\", figsize=(6,3), grid=True, legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f1398",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83c\udfd7 Running on Kubernetes (FYI)\n",
    "```yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata: { name: aiga-demo }\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector: { matchLabels: { app: aiga-demo } }\n",
    "  template:\n",
    "    metadata: { labels: { app: aiga-demo } }\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: orchestrator\n",
    "        image: ghcr.io/montrealai/alpha-aiga:latest@sha256:<signed>\n",
    "        envFrom:\n",
    "        - secretRef: { name: aiga-secrets }\n",
    "        ports:\n",
    "        - containerPort: 8000\n",
    "        - containerPort: 7862\n",
    "```\n",
    "Full SOC-2 artefacts (audit logs, SBOM, cosign signature) ship with the container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9749404b",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf Next steps\n",
    "* Increase `pop_size` or enable GPU for faster evolution.\n",
    "* Modify `curriculum_env.py` to add novel stages.\n",
    "* Plug the JSON API into your own micro-services for autonomous decision loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0000199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u21b3 Graceful shutdown ----------------------------------------------\n",
    "proc.terminate()\n",
    "proc.wait(timeout=10)\n",
    "print('\u2705  Service stopped.')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AI-GA_Meta-Evolution_Demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
