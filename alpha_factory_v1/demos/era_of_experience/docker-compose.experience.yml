version: "3.9"

services:

  orchestrator:
    # Build Alpha‑Factory image in CPU‑slim mode
    build:
      context: ../..                      # → alpha_factory_v1/
      dockerfile: ./Dockerfile            # single multi‑stage Dockerfile :contentReference[oaicite:0]{index=0}
    image: alpha_factory_orchestrator:era
    env_file: ./config.env
    command: python /app/demo/agent_experience_entrypoint.py
    volumes:
      - ./:/app/demo:ro                   # mount demo so entry‑point is visible
    ports:
      - "7860:7860"
    depends_on:
      - ollama

  # Offline fallback LLM (runs even when OPENAI_API_KEY is unset)
  ollama:
    image: ollama/ollama:latest
    tty: true
    environment:
      - OLLAMA_MODELS=mixtral:instruct
    volumes:
      - ollama_models:/root/.ollama       # cache weights between runs

volumes:
  ollama_models:
