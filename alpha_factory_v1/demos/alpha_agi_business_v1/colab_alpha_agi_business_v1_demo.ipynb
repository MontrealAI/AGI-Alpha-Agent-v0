{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha-AGI Business v1 \u2022 Colab Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the introductory **Alpha-Factory** business demo. Works offline\nor upgrades automatically when `OPENAI_API_KEY` is set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 \u00b7 Runtime check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi -L || echo 'GPU not detected - running on CPU'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 \u00b7 Clone repo & install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\nset -e\nif [ ! -d AGI-Alpha-Agent-v0 ]; then\n  git clone --depth 1 https://github.com/MontrealAI/AGI-Alpha-Agent-v0.git\nfi\ncd AGI-Alpha-Agent-v0\npip -q install openai_agents fastapi uvicorn gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 \u00b7 (Optional) Configure your OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\nos.environ['OPENAI_API_KEY'] = getpass.getpass('Enter OpenAI API key (leave blank for offline): ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 \u00b7 Launch orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, re, queue, threading, sys, time\nfrom IPython.display import display, IFrame\n\nroot = 'AGI-Alpha-Agent-v0/alpha_factory_v1/demos/alpha_agi_business_v1'\nproc = subprocess.Popen([sys.executable, '-m', 'alpha_agi_business_v1'], cwd=root, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n\nq = queue.Queue()\n\ndef _tail():\n    for line in proc.stdout:\n        print(line, end='')\n        m = re.search(r'http://localhost:(\\d+)/docs', line)\n        if m:\n            q.put(int(m.group(1)))\n\nthreading.Thread(target=_tail, daemon=True).start()\nport = q.get()\nprint(f'\u23f3 Waiting for REST docs on port {port}...')\nfor _ in range(40):\n    try:\n        import requests\n        if requests.get(f'http://localhost:{port}/healthz').status_code == 200:\n            break\n    except Exception:\n        time.sleep(0.2)\n\niframe = IFrame(src=f'http://localhost:{port}/docs', width='100%', height=600)\ndisplay(iframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 \u00b7 Programmatic API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\nprint('Available agents:', requests.get('http://localhost:8000/agents').json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b \u00b7 Trigger Execution Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\nrequests.post('http://localhost:8000/agent/alpha_execution/trigger')\nprint('execution triggered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 \u00b7 OpenAI Agents bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash",
    "python openai_agents_bridge.py >/tmp/bridge.log 2>&1 &",
    "sleep 2",
    "tail -n 5 /tmp/bridge.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5c \u00b7 Query recent alpha via OpenAI Agents bridge\n",
    "import requests\n",
    "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'recent_alpha'})\n",
    "if resp.status_code == 200:\n",
    "    try:\n",
    "        print('recent alpha:', resp.json())\n",
    "    except ValueError as e:\n",
    "        print('Error decoding JSON response:', e)\n",
    "else:\n",
    "    print(f'Error: Received status code {resp.status_code} with response: {resp.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5d \u00b7 Submit a custom job via the bridge\n",
    "job = {'agent': 'alpha_execution', 'symbol': 'AAPL', 'qty': 1}\n",
    "resp = requests.post('http://localhost:5001/v1/agents/business_helper/invoke', json={'action':'submit_job', 'job': job})\n",
    "print('job submission:', resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 \u00b7 Graceful shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.terminate(); print('\u2705 Orchestrator stopped')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
